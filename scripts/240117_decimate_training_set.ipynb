{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-17T21:55:40.778190331Z",
     "start_time": "2024-01-17T21:55:40.733912616Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from my_paths import dlc_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T23:03:13.871289574Z",
     "start_time": "2024-01-17T23:03:13.825424019Z"
    }
   },
   "id": "62d8a208ee9cc25c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# too many images to label\n",
    "Adding new videos to an existing dataset is not very strrarighforward in DLC, which asks confirmation to add \n",
    "new photorgrams for every video in the dataset. This is a hassle so in the past I have decided to just say yes to \n",
    "everything, which leads to adding a lot of photograms to videos that have already been labeled. These photograms have \n",
    "to be labeled or removed, this function does the later.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbad7c63a24c1f2b"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "labeled_data = dlc_path / \"labeled-data\"\n",
    "\n",
    "for vid_folder in labeled_data.iterdir():\n",
    "    print(f\"decimating images to label en the data set at {labeled_data}...\")\n",
    "    \n",
    "    # todo smarter handling of decimating already labeled folders/videos\n",
    "    label_files = list(vid_folder.glob(\"*.h5\")) \n",
    "    if label_files:\n",
    "        # already labeled\n",
    "        print(f\"{vid_folder} has already been labeled, skipping from decimation\")\n",
    "        label_df = pd.read_hdf(label_files[0])\n",
    "        # images already labeled, should not be deleted\n",
    "        img_names_to_hold = tuple(label_df.index.get_level_values(2))\n",
    "        continue\n",
    "    \n",
    "    imgs = np.asarray(tuple(vid_folder.glob(\"*.png\")))\n",
    "    imgs.sort()\n",
    "    \n",
    "    n_samples = 10\n",
    "    if len(imgs)<= n_samples:\n",
    "        #already few fotograms, no need to decimate.\n",
    "        print(f\"{vid_folder} is already decimated, skipping from decimation\")\n",
    "        continue\n",
    "    print(vid_folder)\n",
    "    idx_to_hold = np.round(np.linspace(0, len(imgs)-1, n_samples, endpoint=True),).astype(int)\n",
    "    idx_to_remove = ~np.in1d(np.arange(0,len(imgs)).astype(int), idx_to_hold, assume_unique=True) \n",
    "    print(len(imgs))\n",
    "    print(idx_to_hold)\n",
    "    print(np.where(idx_to_remove))\n",
    "    \n",
    "    for img in imgs[idx_to_remove]:\n",
    "        print(f\"removing file {img.name}\")\n",
    "        # img.unlink()\n",
    "print(\"... done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T23:20:06.158273566Z",
     "start_time": "2024-01-17T23:20:06.120731864Z"
    }
   },
   "id": "b40d783703320dd6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
